{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valid999/Transformer_GPT3.5-and-facebook-model-for-prompt-engineering/blob/main/openai_api_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e291b18d-a1f0-4068-9290-c9b937567e3e",
      "metadata": {
        "id": "e291b18d-a1f0-4068-9290-c9b937567e3e"
      },
      "source": [
        "# Cracking Open the OpenAI API\n",
        "\n",
        "Code authored by: Shawhin Talebi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25acaea-c334-4254-8635-64270dc6c397",
      "metadata": {
        "id": "f25acaea-c334-4254-8635-64270dc6c397"
      },
      "source": [
        "### set-up"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L4TMqfgLDHm",
        "outputId": "dc999c62-f2ce-4871-8e26-f28313fe0b1e"
      },
      "id": "2L4TMqfgLDHm",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1edd17a3-6cde-4cdf-8f29-c9e1e533d390",
      "metadata": {
        "id": "1edd17a3-6cde-4cdf-8f29-c9e1e533d390"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "# from sk import my_sk #import secret/ key from sk.py file\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0b30b225-6b7c-48ca-8c13-05a75146d6ae",
      "metadata": {
        "id": "0b30b225-6b7c-48ca-8c13-05a75146d6ae"
      },
      "outputs": [],
      "source": [
        "openai.api_key = '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' # use imported sk or just copy-paste it here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c75b3c4-cce9-4d82-888c-078a4e9ae1fa",
      "metadata": {
        "id": "1c75b3c4-cce9-4d82-888c-078a4e9ae1fa"
      },
      "source": [
        "### code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "100350ea-c690-49d3-84cc-84b192c18500",
      "metadata": {
        "id": "100350ea-c690-49d3-84cc-84b192c18500"
      },
      "source": [
        "##### First call"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip uninstall openai"
      ],
      "metadata": {
        "id": "Y4YssUBELeOH"
      },
      "id": "Y4YssUBELeOH",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "eb7a1c4f-b4dc-453f-8e63-bc016f2de35e",
      "metadata": {
        "id": "eb7a1c4f-b4dc-453f-8e63-bc016f2de35e"
      },
      "outputs": [],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f6288eb8-03d7-45f5-9e40-3912afe2a39c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6288eb8-03d7-45f5-9e40-3912afe2a39c",
        "outputId": "e46f1987-c2ff-4e73-cb17-07e1a34b1430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-8Qwcy18S0JevVYR4U8mkv5tABOTns',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1701432584,\n",
              " 'model': 'gpt-3.5-turbo-0613',\n",
              " 'choices': [<OpenAIObject at 0x7d73bb49f650> JSON: {\n",
              "    \"index\": 0,\n",
              "    \"message\": {\n",
              "      \"role\": \"assistant\",\n",
              "      \"content\": \"heart.\\n\\nTrust your instincts.\\n\\nPay attention to your emotions.\\n\\nBe open to new ideas and perspectives.\\n\\nTake time to reflect and introspect.\\n\\nDon't be afraid to take risks and pursue your passions.\\n\\nStay true to yourself and your values.\\n\\nFollow your dreams and never give up.\\n\\nBelieve in yourself and your abilities.\\n\\nKeep learning and growing.\\n\\nBe kind and compassionate to yourself and others.\\n\\nStay present and enjoy each moment.\\n\\nSeek support and guidance when needed.\\n\\nEmbrace change and adapt to new circumstances.\\n\\nLive with gratitude and appreciation.\\n\\nCherish meaningful relationships.\\n\\nFind balance in all aspects of your life.\\n\\nTake care of your physical, mental, and emotional well-being.\\n\\nStay motivated and persevere through challenges.\\n\\nCelebrate your achievements and milestones.\\n\\nNever stop learning and seeking knowledge.\\n\\nHave faith in the journey and enjoy the process.\\n\\nLive life fully and make the most of every opportunity.\"\n",
              "    },\n",
              "    \"finish_reason\": \"stop\"\n",
              "  }],\n",
              " 'usage': <OpenAIObject at 0x7d73bb496890> JSON: {\n",
              "   \"prompt_tokens\": 10,\n",
              "   \"completion_tokens\": 178,\n",
              "   \"total_tokens\": 188\n",
              " },\n",
              " 'system_fingerprint': None}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "chat_completion.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "340f7ccf-c599-443c-89d8-e509039d673b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "340f7ccf-c599-443c-89d8-e509039d673b",
        "outputId": "23f6931e-17f3-4fbd-b3ea-a857f7d5fd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heart.\n",
            "\n",
            "Trust your instincts.\n",
            "\n",
            "Pay attention to your emotions.\n",
            "\n",
            "Be open to new ideas and perspectives.\n",
            "\n",
            "Take time to reflect and introspect.\n",
            "\n",
            "Don't be afraid to take risks and pursue your passions.\n",
            "\n",
            "Stay true to yourself and your values.\n",
            "\n",
            "Follow your dreams and never give up.\n",
            "\n",
            "Believe in yourself and your abilities.\n",
            "\n",
            "Keep learning and growing.\n",
            "\n",
            "Be kind and compassionate to yourself and others.\n",
            "\n",
            "Stay present and enjoy each moment.\n",
            "\n",
            "Seek support and guidance when needed.\n",
            "\n",
            "Embrace change and adapt to new circumstances.\n",
            "\n",
            "Live with gratitude and appreciation.\n",
            "\n",
            "Cherish meaningful relationships.\n",
            "\n",
            "Find balance in all aspects of your life.\n",
            "\n",
            "Take care of your physical, mental, and emotional well-being.\n",
            "\n",
            "Stay motivated and persevere through challenges.\n",
            "\n",
            "Celebrate your achievements and milestones.\n",
            "\n",
            "Never stop learning and seeking knowledge.\n",
            "\n",
            "Have faith in the journey and enjoy the process.\n",
            "\n",
            "Live life fully and make the most of every opportunity.\n"
          ]
        }
      ],
      "source": [
        "# print the chat completion\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e3b38-0bb2-48de-9d3f-ee5013f4a689",
      "metadata": {
        "tags": [],
        "id": "9b0e3b38-0bb2-48de-9d3f-ee5013f4a689"
      },
      "source": [
        "##### max tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "cf02f54e-004e-409b-942d-74a4d855c2d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf02f54e-004e-409b-942d-74a4d855c2d5",
        "outputId": "860dc766-6aa3-47aa-85f4-afc6bfe69898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intuition. \n",
            "\n",
            "Your\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 5)\n",
        "\n",
        "# print the chat completion\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800f966f-7370-46d3-ae12-c955565b9617",
      "metadata": {
        "id": "800f966f-7370-46d3-ae12-c955565b9617"
      },
      "source": [
        "##### n = number of chat completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ad49735c-88c2-4563-a1c6-0020a8905e8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad49735c-88c2-4563-a1c6-0020a8905e8e",
        "outputId": "f5323ce9-e3eb-4934-9e87-fce93f78f697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heart.\n",
            "heart and follow your instincts\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 5,\n",
        "                                n=2)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183ffa97-eb11-4ca9-a8d4-29502ee0cdc6",
      "metadata": {
        "id": "183ffa97-eb11-4ca9-a8d4-29502ee0cdc6"
      },
      "source": [
        "##### temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "638b828b-b323-4cd8-90ea-5106146635a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638b828b-b323-4cd8-90ea-5106146635a0",
        "outputId": "59217782-fe15-44f7-cb93-be3982083bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what I have to say\n",
            "I'm sorry, but\n",
            "your favorite music.\n",
            "Sorry, I am an\n",
            "I'm sorry, but\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to \"}],\n",
        "                                max_tokens = 5,\n",
        "                                n=5,\n",
        "                                temperature=1)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b78dd7ad-5790-441f-981d-60de6c61104d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b78dd7ad-5790-441f-981d-60de6c61104d",
        "outputId": "c173bc6f-e447-4a20-9cd4-f75392cf83af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotions\n",
            "people!\n",
            "\n",
            "Don playing\n",
            "heart and\n",
            "axis\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 2,\n",
        "                                n=5,\n",
        "                                temperature=2)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc228536-a0b6-4a7f-81f7-382c3205ee8a",
      "metadata": {
        "tags": [],
        "id": "cc228536-a0b6-4a7f-81f7-382c3205ee8a"
      },
      "source": [
        "### Demo: Lyric Completion Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ece8e6a6-ebe0-4ff1-b132-e8bc8759e1e6",
      "metadata": {
        "id": "ece8e6a6-ebe0-4ff1-b132-e8bc8759e1e6"
      },
      "outputs": [],
      "source": [
        "# initial prompt with system message and 2 task examples\n",
        "messages_list = [{\"role\":\"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
        "                 {\"role\":\"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
        "                 {\"role\":\"assistant\", \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
        "                 {\"role\":\"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
        "                 {\"role\":\"assistant\", \"content\": \"Your little piece of Heaven turns too dark\"},\n",
        "                 {\"role\":\"user\", \"content\": \"Listen to your\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3b51fdc0-7f91-4524-a27e-739a9fb3f795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b51fdc0-7f91-4524-a27e-739a9fb3f795",
        "outputId": "05d66828-2a75-42ae-dcac-8d179dae460e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the given input.\n",
            "I apologize, but I'm unable to generate a response based on the given\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    # create a chat completion\n",
        "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                    messages=messages_list,\n",
        "                                    max_tokens = 15,\n",
        "                                    n=1,\n",
        "                                    temperature=0)\n",
        "\n",
        "\n",
        "    # print the chat completion\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
        "    messages_list.append(new_message)\n",
        "    time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2168d7-8842-47d0-a7cc-02c5ea505a41",
      "metadata": {
        "id": "4c2168d7-8842-47d0-a7cc-02c5ea505a41"
      },
      "outputs": [],
      "source": [
        "# Actual lyrics:\n",
        "\n",
        "# Listen to your heart when he's calling for you\n",
        "# Listen to your heart, there's nothing else you can do\n",
        "# I don't know where you're going and I don't know why\n",
        "# But listen to your heart before you tell him goodbye"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b588989b-dc89-4c3b-898e-05aec70a8426",
      "metadata": {
        "id": "b588989b-dc89-4c3b-898e-05aec70a8426"
      },
      "source": [
        "##### Crank the temp! (warning: it gets weird)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "5fc19d9a-b1e3-49bd-9c20-f370da0e6bff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc19d9a-b1e3-49bd-9c20-f370da0e6bff",
        "outputId": "44f6f92c-22b2-4207-a874-69fda4f49b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "point harvest prognosisihn nowadaysingu reptON bienmtiem importantSY seedrax\n",
            "Sometimes life was chokingAttributehek성 LackAna<ResourceNo>NoダForeColorFore\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    # create a chat completion\n",
        "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                    messages=messages_list,\n",
        "                                    max_tokens = 15,\n",
        "                                    n=1,\n",
        "                                    temperature=2)\n",
        "\n",
        "    # print the chat completion\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content}\n",
        "    messages_list.append(new_message)\n",
        "    time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73O7fqgtUtZi"
      },
      "id": "73O7fqgtUtZi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}